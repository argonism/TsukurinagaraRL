{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zerokara-chap6-A2C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvppi1H+J1IVnixZvrQZwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argonism/TsukurinagaraRL/blob/master/Zerokara_chap6_A2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE-QKrC0DaLj"
      },
      "source": [
        "ã‚ã‚Œã€$\\pi$ã¨$Q$ã£ã¦ã©ã†é•ã†ã‚“ã ã£ã‘ï¼Ÿ\n",
        "è¡Œå‹•ç¢ºç‡ã¨è¡Œå‹•ä¾¡å€¤ã ã‹ã‚‰ã€æ ¹æœ¬çš„ã«é•ã†ã‹ãª...?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUwB4talX6w7"
      },
      "source": [
        "# A2C\n",
        "- Advantageå­¦ç¿’\n",
        "  - ä»Šã¾ã§ã¯Qå­¦ç¿’ã«1stepå…ˆã¾ã§ã®çŠ¶æ…‹ã‚’ã¿ã¦ããŸãŒã€ã“ã‚Œã‚’2stepå…ˆä»¥ä¸Šã¾ã§ã¿ã‚‹\n",
        "  - $Q(s_t, a_t) \\rightarrow R(t+1) + \\gamma \\bullet R(t+2) + (\\gamma^2) \\bullet max_a[Q(s_{t+2}, a)]$\n",
        "- åˆ†æ•£å­¦ç¿’(Asynchronous\n",
        "  - éåŒæœŸã«è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚\n",
        "  - A2Cã§ã¯ã€ä¸€ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å¯¾ã—ã¦ã€è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚Šå­¦ç¿’ã‚’è¡Œã„ã€åˆ†æ•£å­¦ç¿’ã™ã‚‹ã€‚\n",
        "  - å­¦ç¿’ãŒåŠ¹ç‡çš„ã«ãªã‚‹\n",
        "  - è‡ªç„¶ã¨ãƒ©ãƒ³ãƒ€ãƒ ãªtransitionã«ãªã‚‹ã‹ã‚‰ã€Experience Replayã®å¿…è¦ãŒãªã„\n",
        "- Actor-Critic\n",
        "  - ã“ã‚Œã‹ã‚‰è©³ã—ãã€‚ãŸã—ã‹ã€ä¾¡å€¤åå¾©æ³•ã¨æ–¹ç­–åå¾©æ³•ã‚’åˆã‚ã›ãŸã‚ˆã†ãªã‚‚ã®ã¿ãŸã„ãªèª¬æ˜ã ã£ãŸæ°—ãŒã™ã‚‹ã€‚\n",
        "\n",
        "## Advantageå­¦ç¿’\n",
        "æœªæ¥ã®stepæ•°ã‚’å¢—ã‚„ã›ã°å¢—ã‚„ã™ã»ã©è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ãªã„\n",
        "- æœªæ¥ã®stepæ•°ãŒå¢—ãˆã‚‹ = æœªç¢ºå®šã®è¡Œå‹•ã‚’æ±ºå®šã™ã‚‹å›æ•°ãŒå¢—ãˆã‚‹ = é–“é•ã£ãŸå­¦ç¿’ã‚’ã™ã‚‹ã“ã¨ã‚‚å¢—ãˆã‚‹\n",
        "\n",
        "## åˆ†æ•£å­¦ç¿’\n",
        "\n",
        "## Actor-Critic\n",
        "Actor-Criticã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€çŠ¶æ…‹ã‚’å—ã‘å–ã‚Šã€Actorã¨Criticã‚’è¿”ã™ã€‚\n",
        "\n",
        "Actorã¯è¡Œå‹•ã®æ•°ã ã‘å‡ºåŠ›ã•ã‚Œã€Criticã¯çŠ¶æ…‹ä¾¡å€¤ã‚’ã‚ã‚‰ã‚ã™ä¸€ã¤ã®å€¤ã®ã¿ã‚’è¿”ã™ã€‚\n",
        "\n",
        "ã»ã†ã»ã†...\n",
        "\n",
        "ã¤ã¾ã‚Šã€Actor-Criticã®NNã‹ã‚‰ã¯{è¡Œå‹•ã®ç¨®é¡ + 1}å€‹ã®å‡ºåŠ›ãŒã‚ã‚‹ã€‚ï¼ˆCartpoleãªã‚‰3)\n",
        "(+ 1ã¯çŠ¶æ…‹ä¾¡å€¤ã€‚criticåˆ†)\n",
        "\n",
        "Actorã®å‡ºåŠ›ã¯ã€æ–¹ç­–åå¾©æ³•ã¨åŒã˜ã§çŠ¶æ…‹$s_t$ã®å…¥åŠ›ã«å¯¾ã—ã¦ãã®è¡Œå‹•ãŒã©ã‚Œã ã‘è‰¯ã„ã‚‚ã®ã‹ã‚’å‡ºåŠ›ã™ã‚‹ã€‚(ã¨ã„ã†ã“ã¨ã¯ã€ä¸€ã¤ã®å€¤ãŒå‡ºåŠ›ã•ã‚Œã‚‹ï¼Ÿï¼‰\n",
        "ã“ã®å‡ºåŠ›ã‚’softmaxé–¢æ•°ã‚’é€šã›ã°ã€ãã®è¡Œå‹•ã®æ¡ç”¨ç¢ºç‡ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã€‚\n",
        "\n",
        "critcã¯çŠ¶æ…‹ä¾¡å€¤ã€‚ãã®çŠ¶æ…‹ã«ãªã£ãŸæ™‚ã«ã€ãã®å…ˆã§å¾—ã‚‰ã‚Œã‚‹ã§ã‚ã‚ã†çŠ¶æ…‹ä¾¡å€¤ã®å‰²å¼•å ±é…¬å’Œã€‚\n",
        "\n",
        "Actorå´ã§æœ€å¤§åŒ–ã—ãŸã„ã®ã¯çŠ¶æ…‹$s_t$ã«ãŠã„ã¦ã€çµåˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿$\\theta$ã‚’ä½¿ç”¨ã—ã¦è¡Œå‹•ã—ç¶šã‘ãŸæ™‚ã®å‰²å¼•å ±é…¬å’Œã€‚ã“ã®å‰²å¼•å ±é…¬å’Œã¯æ–¹ç­–å‹¾é…æ³•ã‚’ä½¿ã£ã¦\n",
        "$$J(\\theta, s_t) = E[log\\pi_\\theta(a|s)(Q^\\pi(s,a)-V_s^\\pi)]$$\n",
        "ã¨è¡¨ã›ã‚‹ã€‚ï¼ˆã‚‰ã—ã„ï¼‰\n",
        "\n",
        "- $\\theta$ : ãã‚Œãã‚Œã®çŠ¶æ…‹ã§ã®è¡Œå‹•æ–¹é‡ï¼ˆè¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¨®é¡ã¨ã‚‚è¨€ãˆã‚‹ï¼‰\n",
        "- $\\pi$ : ãã‚Œãã‚Œã®çŠ¶æ…‹ã§ã®è¡Œå‹•ç¢ºç‡\n",
        "- $E[]$: æœŸå¾…å€¤ã‚’è¨ˆç®—ã™ã‚‹(å®Ÿè£…æ™‚ã¯ãƒŸãƒ‹ãƒãƒƒãƒã®å¹³å‡ã¨ã—ã¦è¡¨ã•ã‚Œã‚‹ï¼‰\n",
        "- $log\\pi_\\theta(a|s)$: çŠ¶æ…‹sã®ã¨ãã«è¡Œå‹•aã‚’æ¡ç”¨ã™ã‚‹ç¢ºç‡ã®log(è¡Œå‹•ç¢ºç‡ã®ãƒ­ã‚°)\n",
        "- $Q^\\pi(s,a)$: çŠ¶æ…‹sã§è¡Œå‹•aã‚’æ¡ç”¨ã—ãŸå ´åˆã®è¡Œå‹•ä¾¡å€¤ï¼ˆå®šæ•°ã¨ã—ã¦æ‰±ã†ï¼‰ã€‚Advantageå­¦ç¿’ã§è¨ˆç®—ã™ã‚‹\n",
        "- $V_s^\\pi$: criticã®å‡ºåŠ›ã€‚çŠ¶æ…‹ä¾¡å€¤\n",
        "\n",
        "### æ–¹ç­–ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é …\n",
        "A3C, A2Cã§ã¯Actorã®å­¦ç¿’ã§ã¯ã•ã‚‰ã«ã€Œæ–¹ç­–ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é …ã€ã‚’è¿½åŠ ã—ã€ã“ã‚Œã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¡¨ã•ã‚Œã‚‹ã€‚\n",
        "$$Actor_{entropy} = \\sum^a[\\pi_\\theta(a|s)log\\pi_\\theta(a|s)]$$\n",
        "Î£ã¯è¡Œå‹•ã®ç¨®é¡ã«ã¤ã„ã¦ã®ç·å’Œã‚’è¨ˆç®—ã—ã¦ã„ã‚‹ã€‚\n",
        "æ–¹ç­–ãŒå­¦ç¿’åˆæœŸæ®µéšã§ã€è¡Œå‹•ãŒãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºã¾ã‚‹ã¨ãã€æœ€å¤§ã¨ãªã‚Šã€\n",
        "æ–¹ç­–ã§è¡Œå‹•ãŒä¸€æ–¹ã«æ±ºã¾ã£ã¦ã„ã‚‹ã¨ãã€æœ€å°ã«ãªã‚‹ã€‚\n",
        "Q. ç›®çš„ã‚’çŸ¥ã£ãŸä¸Šã§æ•°å¼ã‚’è¦‹ã¦ã‚‚ã€ãƒ”ãƒ³ã¨ã“ãªã„ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãªã¨ãã«æœ€å¤§ã«ãªã‚‹ã®ã‹...?\n",
        "\n",
        "å­¦ç¿’ã®åˆæœŸæ®µéšã§å‹¾é…ã®å±€æ‰€è§£ã«è½ã¡ã‚‹ã®ã‚’é¿ã‘ã‚‹ç‹™ã„ã€‚\n",
        "\n",
        "### Criticã®å­¦ç¿’\n",
        "$$loss_{Critic} = (Q^\\pi(s, a) - V_s^\\pi)^2$$\n",
        "\n",
        "ã“ã®é–¢æ•°ã®æœ€å°åŒ–ã‚’ç›®æŒ‡ã—ã¦å­¦ç¿’ã™ã‚‹ã€‚\n",
        "\n",
        "çŠ¶æ…‹ä¾¡å€¤ã‚’ãã®çŠ¶æ…‹ã§ã®è¡Œå‹•ä¾¡å€¤ã®ç·å’Œã‹ãªï¼Ÿã«è¿‘ã¥ã‘ãŸã„ã£ã½ãã¦ã€\n",
        "ç¢ºã‹ã«ãã®çŠ¶æ…‹ã§å–ã‚Œã‚‹è¡Œå‹•ã®ä¾¡å€¤ã®ç·å’ŒãŒãã®çŠ¶æ…‹ã®ä¾¡å€¤ã«ãªã‚‹ã£ã¦ã„ã‚‹ã®ã¯ç´å¾—ã§ãã‚‹ã‘ã©ã€\n",
        "è¡Œå‹•ä¾¡å€¤ã‚’æ­£ã—ãè¨­å®šã§ãã¦ã„ã‚‹ã“ã¨ãŒå‰æã¨ãªã‚‹ã®ã§ã€å¯èƒ½ã‹ï¼Ÿã¨ã„ã†æ°—æŒã¡\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN3dNW3vjCT6"
      },
      "source": [
        "# ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# gym==0.17.2 pyvirtualdisplay==1.3.2\n",
        "# xvfb=2:1.19.6-1ubuntu4.4 python-opengl=3.1.0+dfsg-1 ffmpeg=7:3.4.8-0ubuntu0.2\n",
        "# JSAnimation==0.1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install JSAnimation > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vYHqeXSeCMp"
      },
      "source": [
        " import numpy as np\n",
        " import matplotlib.pyplot as plt\n",
        " %matplotlib inline\n",
        " import gym\n",
        "from gym.wrappers import Monitor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm4DcxKAiwzI"
      },
      "source": [
        "# å‹•ç”»ã®æç”»é–¢æ•°ã®å®£è¨€\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import base64\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(640, 400))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[-1]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "def reset_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  for mp4 in mp4list:\n",
        "    os.remove(mp4)\n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True, video_callable=(lambda ep: ep % 10 == 0))\n",
        "  reset_video()\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjaD9q5hy0nr"
      },
      "source": [
        "ENV = 'CartPole-v0'\n",
        "GAMMA = 0.99\n",
        "MAX_STEPS = 200\n",
        "NUM_EPISODES = 1000\n",
        "\n",
        "NUM_PROCESSES = 16\n",
        "NUM_ADVANCED_STEP = 5\n",
        "value_loss_coef = 0.5\n",
        "entropy_coef = 0.01\n",
        "max_grad_norm = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k97Fox4O6rgU"
      },
      "source": [
        "# Advantageå­¦ç¿’ã®ãŸã‚ã®ã‚¯ãƒ©ã‚¹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiPKFzm5d7J"
      },
      "source": [
        "class RolloutStorage(object):\n",
        "  def __init__(self, num_steps, num_processes, obs_shape):\n",
        "    self.observations = torch.zeros(num_steps + 1, num_processes, 4)\n",
        "    # å„è©¦è¡Œã®çµ‚ã‚ã‚Šã‚’ç¤ºã™ãŸã‚ã®å¤‰æ•°ã€‚æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚Œã°1ã€ãªã‘ã‚Œã°0\n",
        "    self.masks = torch.ones(num_steps + 1, num_processes, 1)\n",
        "    self.rewards = torch.zeros(num_steps, num_processes, 1)\n",
        "    self.actions = torch.zeros(num_steps, num_processes, 1).long()\n",
        "\n",
        "    self.returns = torch.zeros(num_steps + 1, num_processes, 1)\n",
        "    self.index = 0\n",
        "  \n",
        "  def insert(self, current_obs, action, reward, mask):\n",
        "    self.observations[self.index + 1].copy_(current_obs)\n",
        "    self.masks[self.index + 1].copy_(mask)\n",
        "    self.rewards[self.index].copy_(reward)\n",
        "    self.actions[self.index].copy_(action)\n",
        "\n",
        "    self.index = (self.index + 1) % NUM_ADVANCED_STEP\n",
        "  \n",
        "  def after_update(self):\n",
        "    ''' advantageå­¦ç¿’åˆ†ã®stepæ•°ã‚’è¶…ãˆãŸã‚‰ã€æ”¹ã‚ã¦æœ€åˆã‹ã‚‰å…¥ã‚Œç›´ã™ '''\n",
        "    self.observations[0].copy_(self.observations[-1])\n",
        "    self.masks[0].copy_(self.masks[-1])\n",
        "  \n",
        "  def compute_returns(self, next_value):\n",
        "    ''' å‰²å¼•å ±é…¬å’Œã‚’è¨ˆç®— '''\n",
        "    self.returns[-1] = next_value\n",
        "    # 5stepç›®ã‹ã‚‰è¨ˆç®—ã—ã¦ã„ã\n",
        "    for ad_step in reversed(range(self.rewards.size(0))):\n",
        "      self.returns[ad_step] = self.returns[ad_step + 1] * \\\n",
        "        GAMMA * self.masks[ad_step + 1] + self.rewards[ad_step]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KNu0CF7BHn4"
      },
      "source": [
        "# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\n",
        "## evaluate_actions\n",
        "\n",
        "> Actorã®å‡ºåŠ›ã¯ã€æ–¹ç­–åå¾©æ³•ã¨åŒã˜ã§çŠ¶æ…‹ ğ‘ ğ‘¡ ã®å…¥åŠ›ã«å¯¾ã—ã¦ãã®è¡Œå‹•ãŒã©ã‚Œã ã‘è‰¯ã„ã‚‚ã®ã‹ã‚’å‡ºåŠ›ã™ã‚‹ã€‚(ã¨ã„ã†ã“ã¨ã¯ã€ä¸€ã¤ã®å€¤ãŒå‡ºåŠ›ã•ã‚Œã‚‹ï¼Ÿï¼‰ ã“ã®å‡ºåŠ›ã‚’softmaxé–¢æ•°ã‚’é€šã›ã°ã€ãã®è¡Œå‹•ã®æ¡ç”¨ç¢ºç‡ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã€‚\n",
        "\n",
        "ã®é€šã‚Šã€actor_outputã‚’softmaxã«é€šã—ãŸã‚‚ã®ãŒè¡Œå‹•ã®ç¢ºç‡å¤‰æ•°ã¨ãªã‚‹ã€‚\n",
        "\n",
        "ãã®ä¸Šã§ã€log_softmax(x) -> log(softmax(x)) ã ã‹ã‚‰ã€\n",
        "\n",
        "log_probs: $\\log\\pi_\\theta(a|s)$\n",
        "\n",
        "action_log_probs: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SRYQ7Ip_lNc"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in, n_mid, n_out):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(n_in, n_mid)\n",
        "    self.fc2 = nn.Linear(n_mid, n_mid)\n",
        "    self.actor = nn.Linear(n_mid, n_out)\n",
        "    self.critic = nn.Linear(n_mid, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    h1 = F.relu(self.fc1(x))\n",
        "    h2 = F.relu(self.fc2(h1))\n",
        "    critic_output = self.critic(h2)\n",
        "    actor_output = self.actor(h2)\n",
        "\n",
        "    return critic_output, actor_output\n",
        "  \n",
        "  def act(self, x):\n",
        "    # ãªã‚“ã˜ã‚ƒã“ã‚Œ...pytorch...\n",
        "    value, actor_output = self(x)\n",
        "    action_probs = F.softmax(actor_output, dim=1)\n",
        "    # å¤šåˆ†ç¢ºç‡å¤‰æ•°(action_probs)ã®ä¸€ç•ªå¤§ãã„ã‚„ã¤ã‚’1ã¤å–ã‚Šå‡ºã—ã¦ãã‚Œã‚‹(0/1)\n",
        "    action = action_probs.multinomial(num_samples=1)\n",
        "    return action\n",
        "  \n",
        "  def get_value(self, x):\n",
        "    value, actor_output = self(x)\n",
        "    return value\n",
        "  \n",
        "  def evaluate_actions(self, x, actions):\n",
        "    ''' ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ›´æ–°æ™‚ã«ä½¿ç”¨ '''\n",
        "    ''' epsilon-greedyæ³•ã¯ä½¿ã‚ãšã€ç¢ºç‡çš„ã«è¡Œå‹•ã‚’æ±ºã‚ã‚‹ã€‚ '''\n",
        "    value, actor_output = self(x)\n",
        "    log_probs = F.log_softmax(actor_output, dim=1)\n",
        "    action_log_probs = log_probs.gather(1, actions)\n",
        "\n",
        "    probs = F.softmax(actor_output, dim=1)\n",
        "    entropy = - (log_probs * probs).sum(-1).mean()\n",
        "\n",
        "    return value, action_log_probs, entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geGnmtlNax3k"
      },
      "source": [
        "\n",
        "advantages: $Q^\\pi(s,a)-V_s^\\pi$\n",
        "\n",
        "critic_loss: $(Q^\\pi(s, a) - V_s^\\pi)^2$\n",
        "\n",
        "action_gain: $J(\\theta, s_t) = E[log\\pi_\\theta(a|s)(Q^\\pi(s,a)-V_s^\\pi)]$\n",
        "\n",
        "\n",
        "$$Actor_{entropy} = \\sum^a[\\pi_\\theta(a|s)log\\pi_\\theta(a|s)]$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gwBq9lI-syb"
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "class Brain(object):\n",
        "  def __init__(self, actor_critic):\n",
        "    self.actor_critic = actor_critic\n",
        "    self.optimizer = optim.Adam(self.actor_critic.parameters(), lr=0.01)\n",
        "\n",
        "  def update(self, rollouts):\n",
        "    obs_shape = rollouts.observations.size()[2:]\n",
        "    num_steps = NUM_ADVANCED_STEP\n",
        "    num_processes = NUM_PROCESSES\n",
        "\n",
        "    values, action_log_probs, entropy = self.actor_critic.evaluate_actions(\n",
        "        rollouts.observations[:-1].view(-1, 4),\n",
        "        rollouts.actions.view(-1, 1)\n",
        "    )\n",
        "\n",
        "    # rollouts.observationã‚„actions.view(-1,1)ã¯(process * advance_step)ã§ 80x4, 80x1ã«ãªã‚‹ã€‚\n",
        "\n",
        "    values = values.view(num_steps, num_processes, 1)\n",
        "    action_log_probs = action_log_probs.view(num_steps, num_processes, 1)\n",
        "\n",
        "    # advantages: è¡Œå‹•ä¾¡å€¤ - çŠ¶æ…‹ä¾¡å€¤\n",
        "    advantages = rollouts.returns[:-1] - values\n",
        "    # criticã®loss\n",
        "    value_loss = advantages.pow(2).mean()\n",
        "    # actorã®gainã‚’è¨ˆç®—ã™ã‚‹ã‚‰ã—ã„ãŒã€ã¨ã“ã‚ã§gainã£ã¦ä½•ï¼Ÿèã„ãŸã“ã¨ãªã„ã‘ã©\n",
        "    # J(theta, s_t)ã‚’è¨ˆç®—ã—ã¦ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚action_log_probsãŒlog\\pi(s|a)ã ã—ã€‚meanã§æœŸå¾…å€¤ã‹ã€‚\n",
        "    action_gain = (action_log_probs * advantages.detach()).mean()\n",
        "    # èª¤å·®é–¢æ•°ã®ç·å’Œã€‚ã“ã‚Œãªã‚“ã ã‚ã€‚criticã¨actionã¯ç‹¬ç«‹ã—ã¦å­¦ç¿’ã•ã›ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã®ã‹ã€‚\n",
        "    # èª¬æ˜ã«å‡ºã¦ãã¦ãªã„ã¨æ€ã‚ã‚Œã‚‹\n",
        "    total_loss = (value_loss * value_loss_coef - action_gain - entropy * entropy_coef)\n",
        "\n",
        "    self.actor_critic.train()\n",
        "    self.optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    nn.utils.clip_grad_norm_(self.actor_critic.parameters(), max_grad_norm)\n",
        "    # ä¸€æ°—ã«çµåˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤‰åŒ–ã—ã™ããªã„ã‚ˆã†ã«ã€å‹¾é…ã®å¤§ãã•ã¯æœ€å¤§0.5ã¾ã§\n",
        "\n",
        "    self.optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KIsLGuOgvDl"
      },
      "source": [
        "import copy\n",
        "\n",
        "class Environment:\n",
        "  def run(self):\n",
        "    ''' ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œ '''\n",
        "    envs = [wrap_env(gym.make(ENV)) for i in range(NUM_PROCESSES)]\n",
        "\n",
        "    n_in = envs[0].observation_space.shape[0]\n",
        "    n_out = envs[0].action_space.n\n",
        "    n_mid = 32\n",
        "    actor_critic = Net(n_in, n_mid, n_out)\n",
        "\n",
        "    global_brain = Brain(actor_critic)\n",
        "\n",
        "    obs_shape = n_in\n",
        "    current_obs = torch.zeros(NUM_PROCESSES, obs_shape)\n",
        "    rollouts = RolloutStorage(NUM_ADVANCED_STEP, NUM_PROCESSES, obs_shape)\n",
        "    episode_rewards = torch.zeros([NUM_PROCESSES, 1])\n",
        "    final_rewards = torch.zeros([NUM_PROCESSES, 1])\n",
        "    obs_np = np.zeros([NUM_PROCESSES, obs_shape])\n",
        "    reward_np = np.zeros([NUM_PROCESSES, 1])\n",
        "    done_np = np.zeros([NUM_PROCESSES, 1])\n",
        "    each_step = np.zeros(NUM_PROCESSES)\n",
        "    episode = 0\n",
        "\n",
        "    obs = [envs[i].reset() for i in range(NUM_PROCESSES)]\n",
        "    obs = np.array(obs)\n",
        "    obs = torch.from_numpy(obs).float()\n",
        "    current_obs = obs\n",
        "\n",
        "    rollouts.observations[0].copy_(current_obs)\n",
        "\n",
        "    for j in range(NUM_EPISODES * NUM_PROCESSES):\n",
        "      # Advancedå­¦ç¿’ã®ãŸã‚ã®ãƒ«ãƒ¼ãƒ—\n",
        "      for step in range(NUM_ADVANCED_STEP):\n",
        "        with torch.no_grad():\n",
        "          action = actor_critic.act(rollouts.observations[step])\n",
        "        actions = action.squeeze(1).numpy()\n",
        "\n",
        "        # 1stepè¸ã‚€\n",
        "        for i in range(NUM_PROCESSES):\n",
        "          obs_np[i], reward_np[i], done_np[i], _ = envs[i].step(actions[i])\n",
        "          if done_np[i]:\n",
        "            if i == 0:\n",
        "              print(f'{episode} Episode: Finished after {each_step[i] + 1} time steps')\n",
        "              episode += 1\n",
        "            \n",
        "            # çµ‚äº†æ™‚ã®å ±é…¬ã®è¨­å®š\n",
        "            if each_step[i] < 195:\n",
        "              reward_np[i] = -1.0\n",
        "            else:\n",
        "              reward_np[i] = 1.0\n",
        "            \n",
        "            each_step[i] = 0\n",
        "            obs_np[i] = envs[i].reset()\n",
        "\n",
        "          else:\n",
        "            reward_np[i] = 0.0\n",
        "            each_step[i] += 1\n",
        "        # 1stepçµ‚äº†\n",
        "\n",
        "        reward = torch.from_numpy(reward_np).float()\n",
        "        episode_rewards += reward\n",
        "\n",
        "        # æœ€å¾Œã®stepã ã£ãŸã‚‰0.0ã€‚ãã‚Œä»¥å¤–ãªã‚‰1.0\n",
        "        masks = torch.FloatTensor([[0.0] if done_ else [1.0] for done_ in done_np])\n",
        "\n",
        "        final_rewards *= masks\n",
        "\n",
        "        final_rewards += (1 - masks) * episode_rewards\n",
        "\n",
        "        episode_rewards *= masks\n",
        "\n",
        "        current_obs *= masks\n",
        "\n",
        "        obs = torch.from_numpy(obs_np).float()\n",
        "        current_obs = obs\n",
        "\n",
        "        rollouts.insert(current_obs, action.data, reward, masks)\n",
        "    # Advancedå­¦ç¿’ã®ãŸã‚ã®ãƒ«ãƒ¼ãƒ—çµ‚äº†\n",
        "      with torch.no_grad():\n",
        "        next_value = actor_critic.get_value(rollouts.observations[-1]).detach()\n",
        "      \n",
        "      rollouts.compute_returns(next_value)\n",
        "\n",
        "      global_brain.update(rollouts)\n",
        "      rollouts.after_update()\n",
        "\n",
        "      # \n",
        "      if final_rewards.sum().numpy() >= NUM_PROCESSES:\n",
        "        print('é€£ç¶šæˆåŠŸ')\n",
        "        show_video()\n",
        "        break\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "vS0vFNqE3wqO",
        "outputId": "380e5267-fcab-4c1b-a25c-4113a5d68cac"
      },
      "source": [
        "cartpole_env = Environment()\n",
        "cartpole_env.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Episode: Finished after 29.0 time steps\n",
            "1 Episode: Finished after 16.0 time steps\n",
            "2 Episode: Finished after 15.0 time steps\n",
            "3 Episode: Finished after 19.0 time steps\n",
            "4 Episode: Finished after 17.0 time steps\n",
            "5 Episode: Finished after 22.0 time steps\n",
            "6 Episode: Finished after 11.0 time steps\n",
            "7 Episode: Finished after 61.0 time steps\n",
            "8 Episode: Finished after 20.0 time steps\n",
            "9 Episode: Finished after 34.0 time steps\n",
            "10 Episode: Finished after 25.0 time steps\n",
            "11 Episode: Finished after 18.0 time steps\n",
            "12 Episode: Finished after 94.0 time steps\n",
            "13 Episode: Finished after 47.0 time steps\n",
            "14 Episode: Finished after 117.0 time steps\n",
            "15 Episode: Finished after 86.0 time steps\n",
            "16 Episode: Finished after 21.0 time steps\n",
            "17 Episode: Finished after 21.0 time steps\n",
            "18 Episode: Finished after 189.0 time steps\n",
            "19 Episode: Finished after 139.0 time steps\n",
            "20 Episode: Finished after 128.0 time steps\n",
            "21 Episode: Finished after 131.0 time steps\n",
            "22 Episode: Finished after 86.0 time steps\n",
            "23 Episode: Finished after 162.0 time steps\n",
            "24 Episode: Finished after 93.0 time steps\n",
            "25 Episode: Finished after 200.0 time steps\n",
            "26 Episode: Finished after 69.0 time steps\n",
            "27 Episode: Finished after 200.0 time steps\n",
            "é€£ç¶šæˆåŠŸ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb7twQ_L-td6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}